# Resnet50-cats_vs_dogs

[![zhihu](https://img.shields.io/badge/çŸ¥ä¹-zhihu-blue)](https://zhuanlan.zhihu.com/p/676430630)
[![swanlab](https://img.shields.io/badge/çŒ«ç‹—åˆ†ç±»-SwanLab-438440)](https://swanlab.cn/@ZeyiLin/Cats_Dogs_Classification/runs/jzo93k112f15pmx14vtxf/chart)

çŒ«ç‹—åˆ†ç±»æ˜¯è®¡ç®—æœºè§†è§‰æœ€åŸºç¡€çš„ä»»åŠ¡ä¹‹ä¸€â€”â€”å¦‚æœè¯´å®ŒæˆMNISTæ‰‹å†™ä½“è¯†åˆ«æ˜¯å®ç°CVçš„â€œHello Worldâ€ï¼Œé‚£çŒ«ç‹—åˆ†ç±»å°±æ˜¯æ—…ç¨‹çš„ä¸‹ä¸€ç«™ï½ã€‚

è¿™ç¯‡æ–‡ç« æˆ‘å°†å¸¦å¤§å®¶ä½¿ç”¨SwanLabã€PyTorchã€Gradioä¸‰ä¸ªå¼€æºå·¥å…·ï¼Œå®Œæˆä»**æ•°æ®é›†å‡†å¤‡ã€ä»£ç ç¼–å†™ã€å¯è§†åŒ–è®­ç»ƒ**åˆ°**æ„å»ºDemoç½‘é¡µ**çš„å…¨è¿‡ç¨‹ã€‚

> ğŸ”¥ å®éªŒè¿‡ç¨‹å¯çœ‹è¿™ä¸ªç½‘é¡µï¼š[![swanlab](https://img.shields.io/badge/çŒ«ç‹—åˆ†ç±»-SwanLab-438440)](https://github.com/swanhubx/swanlab)  
> ä»£ç ï¼š[Github](https://github.com/xiaolin199912/Resnet50-cats_vs_dogs)
> åœ¨çº¿Demoï¼š[SwanHub](https://swanhub.co/ZeYiLin/Resnet50-cats_vs_dogs/demo)ã€[HuggingFace](https://huggingface.co/spaces/TheEeeeLin/Resnet50-cats_vs_dogs)  
> æ•°æ®é›†ï¼š[ç™¾åº¦äº‘](https://pan.baidu.com/s/1qYa13SxFM0AirzDyFMy0mQ) æå–ç : 1ybm  
> ä¸‰ä¸ªå¼€æºåº“ï¼š[SwanLab](https://github.com/SwanHubX/SwanLab)ã€[Pytorch](https://github.com/pytorch/pytorch)ã€[Gradio](https://github.com/gradio-app/gradio)


- ğŸ”¥2024/5/1æ›´æ–°ï¼šè¡¥å……swanlabäº‘ç«¯ç‰ˆå†…å®¹ã€‚
- ğŸ”¥2024/3/17æ›´æ–°ï¼šå¢åŠ swanlabä¸Šä¼ å›¾åƒçš„ä»£ç ã€‚

![](readme_files/1.png)


# 1. å‡†å¤‡éƒ¨åˆ†

## 1.1 å®‰è£…Pythonåº“

éœ€è¦å®‰è£…ä¸‹é¢è¿™4ä¸ªåº“ï¼š

```bash
torch>=1.12.0
torchvision>=0.13.0
swanlab>=0.3.3
gradio
```

å®‰è£…å‘½ä»¤ï¼š

```bash
pip install torch>=1.12.0 torchvision>=0.13.0 swanlab>=0.3.3 gradio
```

## 1.2 åˆ›å»ºæ–‡ä»¶ç›®å½•

ç°åœ¨æ‰“å¼€1ä¸ªæ–‡ä»¶å¤¹ï¼Œæ–°å»ºä¸‹é¢è¿™5ä¸ªæ–‡ä»¶ï¼š ![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](readme_files/1.png)

å®ƒä»¬å„è‡ªçš„ä½œç”¨åˆ†åˆ«æ˜¯ï¼š

*   `checkpoint`ï¼šè¿™ä¸ªæ–‡ä»¶å¤¹ç”¨äºå­˜å‚¨è®­ç»ƒè¿‡ç¨‹ä¸­ç”Ÿæˆçš„æ¨¡å‹æƒé‡ã€‚
*   `datasets`ï¼šè¿™ä¸ªæ–‡ä»¶å¤¹ç”¨äºæ”¾ç½®æ•°æ®é›†ã€‚
*   `app.py`ï¼šè¿è¡ŒGradio Demoçš„Pythonè„šæœ¬ã€‚
*   `load_datasets.py`ï¼šè´Ÿè´£è½½å…¥æ•°æ®é›†ï¼ŒåŒ…å«äº†æ•°æ®çš„é¢„å¤„ç†ã€åŠ è½½ç­‰æ­¥éª¤ï¼Œç¡®ä¿æ•°æ®ä»¥é€‚å½“çš„æ ¼å¼æä¾›ç»™æ¨¡å‹ä½¿ç”¨ã€‚
*   `train.py`ï¼šæ¨¡å‹è®­ç»ƒçš„æ ¸å¿ƒè„šæœ¬ã€‚å®ƒåŒ…å«äº†æ¨¡å‹çš„è½½å…¥ã€è®­ç»ƒå¾ªç¯ã€æŸå¤±å‡½æ•°çš„é€‰æ‹©ã€ä¼˜åŒ–å™¨çš„é…ç½®ç­‰å…³é”®ç»„æˆéƒ¨åˆ†ï¼Œç”¨äºæŒ‡å¯¼å¦‚ä½•ä½¿ç”¨æ•°æ®æ¥è®­ç»ƒæ¨¡å‹ã€‚

## 1.3 ä¸‹è½½çŒ«ç‹—åˆ†ç±»æ•°æ®é›†

æ•°æ®é›†æ¥æºæ˜¯Modelscopeä¸Šçš„[çŒ«ç‹—åˆ†ç±»æ•°æ®é›†](https://modelscope.cn/datasets/tany0699/cats_and_dogs/summary)ï¼ŒåŒ…å«275å¼ å›¾åƒçš„æ•°æ®é›†å’Œ70å¼ å›¾åƒçš„æµ‹è¯•é›†ï¼Œä¸€å…±ä¸åˆ°10MBã€‚
æˆ‘å¯¹æ•°æ®åšäº†ä¸€äº›æ•´ç†ï¼Œæ‰€ä»¥æ›´æ¨èä½¿ç”¨ä¸‹é¢çš„ç™¾åº¦ç½‘ç›˜é“¾æ¥ä¸‹è½½ï¼š

> ç™¾åº¦ç½‘ç›˜ï¼šé“¾æ¥: <https://pan.baidu.com/s/1qYa13SxFM0AirzDyFMy0mQ> æå–ç : 1ybm

![alt text](/readme_files/2.png)

å°†æ•°æ®é›†æ”¾å…¥`datasets`æ–‡ä»¶å¤¹ï¼š

![alt text](/readme_files/3.png)

okï¼Œç°åœ¨æˆ‘ä»¬å¼€å§‹è®­ç»ƒéƒ¨åˆ†ï¼

> psï¼šå¦‚æœä½ æƒ³è¦ç”¨æ›´å¤§è§„æ¨¡çš„æ•°æ®æ¥è®­ç»ƒçŒ«ç‹—åˆ†ç±»æ¨¡å‹ï¼Œè¯·å‰å¾€æ–‡æœ«çš„ç›¸å…³é“¾æ¥ã€‚

# 2. è®­ç»ƒéƒ¨åˆ†

psï¼šå¦‚æœæƒ³ç›´æ¥çœ‹å®Œæ•´ä»£ç å’Œæ•ˆæœï¼Œå¯ç›´æ¥è·³è½¬åˆ°ç¬¬**2.9**ã€‚

## 2.1 load_datasets.py

æˆ‘ä»¬é¦–å…ˆéœ€è¦åˆ›å»º1ä¸ªç±»`DatasetLoader`ï¼Œå®ƒçš„ä½œç”¨æ˜¯å®Œæˆæ•°æ®é›†çš„è¯»å–å’Œé¢„å¤„ç†ï¼Œæˆ‘ä»¬å°†å®ƒå†™åœ¨`load_datasets.py`ä¸­ã€‚
åœ¨å†™è¿™ä¸ªç±»ä¹‹å‰ï¼Œå…ˆåˆ†æä¸€ä¸‹æ•°æ®é›†ã€‚
åœ¨datasetsç›®å½•ä¸‹ï¼Œ`train.csv`å’Œ`val.csv`åˆ†åˆ«è®°å½•äº†è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„å›¾åƒç›¸å¯¹è·¯å¾„ï¼ˆç¬¬ä¸€åˆ—æ˜¯å›¾åƒçš„ç›¸å¯¹è·¯å¾„ï¼Œç¬¬äºŒåˆ—æ˜¯æ ‡ç­¾ï¼Œ0ä»£è¡¨çŒ«ï¼Œ1ä»£è¡¨ç‹—ï¼‰ï¼š

![alt text](/readme_files/image.png)

![alt text](/readme_files/image-1.png)

å·¦å›¾ä½œä¸ºtrain.csvï¼Œå³å›¾ä¸ºtrainæ–‡ä»¶å¤¹ä¸­çš„catæ–‡ä»¶å¤¹ä¸­çš„å›¾åƒã€‚

é‚£ä¹ˆæˆ‘ä»¬çš„ç›®æ ‡å°±å¾ˆæ˜ç¡®ï¼š

1.  è§£æè¿™ä¸¤ä¸ªcsvæ–‡ä»¶ï¼Œè·å–å›¾åƒç›¸å¯¹è·¯å¾„å’Œæ ‡ç­¾
2.  æ ¹æ®ç›¸å¯¹è·¯å¾„è¯»å–å›¾åƒ
3.  å¯¹å›¾åƒåšé¢„å¤„ç†
4.  è¿”å›é¢„å¤„ç†åçš„å›¾åƒå’Œå¯¹åº”æ ‡ç­¾

æ˜ç¡®äº†ç›®æ ‡åï¼Œç°åœ¨æˆ‘ä»¬å¼€å§‹å†™`DatasetLoader`ç±»ï¼š

```python
import csv
import os
from torchvision import transforms
from PIL import Image
from torch.utils.data import Dataset

class DatasetLoader(Dataset):
    def __init__(self, csv_path):
        self.csv_file = csv_path
        with open(self.csv_file, 'r') as file:
            self.data = list(csv.reader(file))

        self.current_dir = os.path.dirname(os.path.abspath(__file__))

    def preprocess_image(self, image_path):
        full_path = os.path.join(self.current_dir, 'datasets', image_path)
        image = Image.open(full_path)
        image_transform = transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])

        return image_transform(image)

    def __getitem__(self, index):
        image_path, label = self.data[index]
        image = self.preprocess_image(image_path)
        return image, int(label)

    def __len__(self):
        return len(self.data)
```

`DatasetLoader`ç±»ç”±å››ä¸ªéƒ¨åˆ†ç»„æˆï¼š

1.  `__init__`ï¼šåŒ…å«1ä¸ªè¾“å…¥å‚æ•°csv\_pathï¼Œåœ¨å¤–éƒ¨ä¼ å…¥`csv_path`åï¼Œå°†è¯»å–åçš„æ•°æ®å­˜å…¥`self.data`ä¸­ã€‚`self.current_dir`åˆ™æ˜¯è·å–äº†å½“å‰ä»£ç æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„ï¼Œä¸ºåç»­è¯»å–å›¾åƒåšå‡†å¤‡ã€‚

2.  `preprocess_image`ï¼šæ­¤å‡½æ•°ç”¨äºå›¾åƒé¢„å¤„ç†ã€‚é¦–å…ˆï¼Œå®ƒæ„é€ å›¾åƒæ–‡ä»¶çš„ç»å¯¹è·¯å¾„ï¼Œç„¶åä½¿ç”¨PILåº“æ‰“å¼€å›¾åƒã€‚æ¥ç€ï¼Œå®šä¹‰äº†ä¸€ç³»åˆ—å›¾åƒå˜æ¢ï¼šè°ƒæ•´å›¾åƒå¤§å°è‡³256x256ã€è½¬æ¢å›¾åƒä¸ºå¼ é‡ã€å¯¹å›¾åƒè¿›è¡Œæ ‡å‡†åŒ–å¤„ç†ï¼Œæœ€ç»ˆï¼Œè¿”å›é¢„å¤„ç†åçš„å›¾åƒã€‚

3.  `__getitem__`ï¼šå½“æ•°æ®é›†ç±»è¢«å¾ªç¯è°ƒç”¨æ—¶ï¼Œ`__getitem__`æ–¹æ³•ä¼šè¿”å›æŒ‡å®šç´¢å¼•indexçš„æ•°æ®ï¼Œå³å›¾åƒå’Œæ ‡ç­¾ã€‚é¦–å…ˆï¼Œå®ƒæ ¹æ®ç´¢å¼•ä»`self.data`ä¸­å–å‡ºå›¾åƒè·¯å¾„å’Œæ ‡ç­¾ã€‚ç„¶åï¼Œè°ƒç”¨`preprocess_image`æ–¹æ³•æ¥å¤„ç†å›¾åƒæ•°æ®ã€‚æœ€åï¼Œå°†å¤„ç†åçš„å›¾åƒæ•°æ®å’Œæ ‡ç­¾è½¬æ¢ä¸ºæ•´å‹åè¿”å›ã€‚

4.  `__len__`ï¼šç”¨äºè¿”å›æ•°æ®é›†çš„æ€»å›¾åƒæ•°é‡ã€‚

## 2.2 è½½å…¥æ•°æ®é›†
> ä»æœ¬èŠ‚å¼€å§‹ï¼Œä»£ç å°†å†™åœ¨`train.py`ä¸­ã€‚

```python
from torch.utils.data import DataLoader
from load_datasets import DatasetLoader

batch_size = 8

TrainDataset = DatasetLoader("datasets/train.csv")
ValDataset = DatasetLoader("datasets/val.csv")
TrainDataLoader = DataLoader(TrainDataset, batch_size=batch_size, shuffle=True)
ValDataLoader = DataLoader(ValDataset, batch_size=batch_size, shuffle=False)
```

æˆ‘ä»¬ä¼ å…¥é‚£ä¸¤ä¸ªcsvæ–‡ä»¶çš„è·¯å¾„å®ä¾‹åŒ–`DatasetLoader`ç±»ï¼Œç„¶åç”¨PyTorchçš„`DataLoader`åšä¸€å±‚å°è£…ã€‚`DataLoader`å¯ä»¥å†ä¼ å…¥ä¸¤ä¸ªå‚æ•°ï¼š

*   `batch_size`ï¼šå®šä¹‰äº†æ¯ä¸ªæ•°æ®æ‰¹æ¬¡åŒ…å«å¤šå°‘å¼ å›¾åƒã€‚åœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸ä¸ä¼šä¸€æ¬¡æ€§åœ°å¤„ç†æ‰€æœ‰æ•°æ®ï¼Œè€Œæ˜¯å°†æ•°æ®åˆ’åˆ†ä¸ºå°æ‰¹æ¬¡ã€‚è¿™æœ‰åŠ©äºæ¨¡å‹æ›´å¿«åœ°å­¦ä¹ ï¼Œå¹¶ä¸”è¿˜å¯ä»¥èŠ‚çœå†…å­˜ã€‚åœ¨è¿™é‡Œæˆ‘ä»¬å®šä¹‰batch\_size = 8ï¼Œå³æ¯ä¸ªæ‰¹æ¬¡å°†åŒ…å«8ä¸ªå›¾åƒã€‚
*   `shuffle`ï¼šå®šä¹‰äº†æ˜¯å¦åœ¨æ¯ä¸ªå¾ªç¯è½®æ¬¡ï¼ˆepochï¼‰å¼€å§‹æ—¶éšæœºæ‰“ä¹±æ•°æ®ã€‚è¿™é€šå¸¸ç”¨äºè®­ç»ƒæ•°æ®é›†ä»¥ä¿è¯æ¯ä¸ªepochçš„æ•°æ®é¡ºåºä¸åŒï¼Œä»è€Œå¸®åŠ©æ¨¡å‹æ›´å¥½åœ°æ³›åŒ–ã€‚å¦‚æœè®¾ç½®ä¸ºTrueï¼Œé‚£ä¹ˆåœ¨æ¯ä¸ªepochå¼€å§‹æ—¶ï¼Œæ•°æ®å°†è¢«æ‰“ä¹±ã€‚åœ¨è¿™é‡Œæˆ‘ä»¬è®©è®­ç»ƒæ—¶æ‰“ä¹±ï¼Œæµ‹è¯•æ—¶ä¸æ‰“ä¹±ã€‚

## 2.3 è½½å…¥ResNet50æ¨¡å‹

æ¨¡å‹æˆ‘ä»¬é€‰ç”¨ç»å…¸çš„**ResNet50**ï¼Œæ¨¡å‹çš„å…·ä½“åŸç†æœ¬æ–‡å°±ä¸ç»†è¯´äº†ï¼Œé‡ç‚¹æ”¾åœ¨å·¥ç¨‹å®ç°ä¸Šã€‚
æˆ‘ä»¬ä½¿ç”¨**torchvision**æ¥åˆ›å»º1ä¸ªresnet50æ¨¡å‹ï¼Œå¹¶è½½å…¥åœ¨Imagenet1kæ•°æ®é›†ä¸Šé¢„è®­ç»ƒå¥½çš„æƒé‡ï¼š

```python
from torchvision.models import ResNet50_Weights

# åŠ è½½é¢„è®­ç»ƒçš„ResNet50æ¨¡å‹
model = torchvision.models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)
```

å› ä¸ºçŒ«ç‹—åˆ†ç±»æ˜¯ä¸ª2åˆ†ç±»ä»»åŠ¡ï¼Œè€Œtorchvisionæä¾›çš„resnet50é»˜è®¤æ˜¯1000åˆ†ç±»ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦æŠŠæ¨¡å‹æœ€åçš„å…¨è¿æ¥å±‚çš„è¾“å‡ºç»´åº¦æ›¿æ¢ä¸º2ï¼š

```python
from torchvision.models import ResNet50_Weights

num_classes=2

# åŠ è½½é¢„è®­ç»ƒçš„ResNet50æ¨¡å‹
model = torchvision.models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)

# å°†å…¨è¿æ¥å±‚çš„è¾“å‡ºç»´åº¦æ›¿æ¢ä¸ºnum_classes
in_features = model.fc.in_features
model.fc = torch.nn.Linear(in_features, num_classes)
```

## 2.4 è®¾ç½®cuda/mps/cpu

å¦‚æœä½ çš„ç”µè„‘æ˜¯**è‹±ä¼Ÿè¾¾æ˜¾å¡**ï¼Œé‚£ä¹ˆcudaå¯ä»¥æå¤§åŠ é€Ÿä½ çš„è®­ç»ƒï¼›
å¦‚æœä½ çš„ç”µè„‘æ˜¯**Macbook Apple Silliconï¼ˆMç³»åˆ—èŠ¯ç‰‡ï¼‰**ï¼Œé‚£ä¹ˆmpsåŒæ ·å¯ä»¥æå¤§åŠ é€Ÿä½ çš„è®­ç»ƒï¼›
å¦‚æœéƒ½ä¸æ˜¯ï¼Œé‚£å°±é€‰ç”¨cpuï¼š

```python
#æ£€æµ‹æ˜¯å¦æ”¯æŒmps
try:
    use_mps = torch.backends.mps.is_available()
except AttributeError:
    use_mps = False

#æ£€æµ‹æ˜¯å¦æ”¯æŒcuda
if torch.cuda.is_available():
    device = "cuda"
elif use_mps:
    device = "mps"
else:
    device = "cpu"
```

å°†æ¨¡å‹åŠ è½½åˆ°å¯¹åº”çš„deviceä¸­ï¼š

```python
model.to(torch.device(device))
```

## 2.5 è®¾ç½®è¶…å‚æ•°ã€ä¼˜åŒ–å™¨ã€æŸå¤±å‡½æ•°

**è¶…å‚æ•°**
è®¾ç½®è®­ç»ƒè½®æ¬¡ä¸º20è½®ï¼Œå­¦ä¹ ç‡ä¸º1e-4ï¼Œè®­ç»ƒæ‰¹æ¬¡ä¸º8ï¼Œåˆ†ç±»æ•°ä¸º2åˆ†ç±»ã€‚

```python
num_epochs = 20
lr = 1e-4
batch_size = 8
num_classes = 2
```

### æŸå¤±å‡½æ•°ä¸ä¼˜åŒ–å™¨

è®¾ç½®æŸå¤±å‡½æ•°ä¸ºäº¤å‰ç†µæŸå¤±ï¼Œä¼˜åŒ–å™¨ä¸ºAdamã€‚

```python
criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=lr)
```

## 2.6 åˆå§‹åŒ–SwanLab

åœ¨è®­ç»ƒä¸­æˆ‘ä»¬ä½¿ç”¨`swanlab`åº“ä½œä¸ºå®éªŒç®¡ç†ä¸æŒ‡æ ‡å¯è§†åŒ–å·¥å…·ã€‚
[swanlab](https://github.com/SwanHubX/SwanLab)æ˜¯ä¸€ä¸ªç±»ä¼¼Tensorboardçš„å¼€æºè®­ç»ƒå›¾è¡¨å¯è§†åŒ–åº“ï¼Œæœ‰ç€æ›´è½»é‡çš„ä½“ç§¯ä¸æ›´å‹å¥½çš„APIï¼Œé™¤äº†èƒ½è®°å½•æŒ‡æ ‡ï¼Œè¿˜èƒ½è‡ªåŠ¨è®°å½•è®­ç»ƒçš„loggingã€ç¡¬ä»¶ç¯å¢ƒã€Pythonç¯å¢ƒã€è®­ç»ƒæ—¶é—´ç­‰ä¿¡æ¯ã€‚

![alt text](/readme_files/image-2.png)

### è®¾ç½®åˆå§‹åŒ–é…ç½®å‚æ•°

swanlabåº“ä½¿ç”¨`swanlab.init`è®¾ç½®å®éªŒåã€å®éªŒä»‹ç»å’Œè®°å½•è¶…å‚æ•°ã€‚

```python
import swanlab

swanlab.init(
    # è®¾ç½®å®éªŒå
    experiment_name="ResNet50",
    # è®¾ç½®å®éªŒä»‹ç»
    description="Train ResNet50 for cat and dog classification.",
    # è®°å½•è¶…å‚æ•°
    config={
        "model": "resnet50",
        "optim": "Adam",
        "lr": lr,
        "batch_size": batch_size,
        "num_epochs": num_epochs,
        "num_class": num_classes,
        "device": device,
    }
)
```

### è·Ÿè¸ªå…³é”®æŒ‡æ ‡

swanlabåº“ä½¿ç”¨`swanlab.log`æ¥è®°å½•å…³é”®æŒ‡æ ‡ï¼Œå…·ä½“ä½¿ç”¨æ¡ˆä¾‹è§2.7å’Œ2.8ã€‚

## 2.7 è®­ç»ƒå‡½æ•°

æˆ‘ä»¬å®šä¹‰1ä¸ªè®­ç»ƒå‡½æ•°`train`ï¼š

```python
def train(model, device, train_dataloader, optimizer, criterion, epoch):
    model.train()
    for iter, (inputs, labels) in enumerate(train_loader):
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        print('Epoch [{}/{}], Iteration [{}/{}], Loss: {:.4f}'.format(epoch, num_epochs, iter + 1, len(TrainDataLoader),
                                                                      loss.item()))
        swanlab.log({"train_loss": loss.item()})
```

è®­ç»ƒçš„é€»è¾‘å¾ˆç®€å•ï¼šæˆ‘ä»¬å¾ªç¯è°ƒç”¨`train_dataloader`ï¼Œæ¯æ¬¡å–å‡º1ä¸ªbatch\_sizeçš„å›¾åƒå’Œæ ‡ç­¾ï¼Œä¼ å…¥åˆ°resnet50æ¨¡å‹ä¸­å¾—åˆ°é¢„æµ‹ç»“æœï¼Œå°†ç»“æœå’Œæ ‡ç­¾ä¼ å…¥æŸå¤±å‡½æ•°ä¸­è®¡ç®—äº¤å‰ç†µæŸå¤±ï¼Œæœ€åæ ¹æ®æŸå¤±è®¡ç®—åå‘ä¼ æ’­ï¼ŒAdamä¼˜åŒ–å™¨æ‰§è¡Œæ¨¡å‹å‚æ•°æ›´æ–°ï¼Œå¾ªç¯å¾€å¤ã€‚

åœ¨è®­ç»ƒä¸­æˆ‘ä»¬æœ€å…³å¿ƒçš„æŒ‡æ ‡æ˜¯æŸå¤±å€¼`loss`ï¼Œæ‰€ä»¥æˆ‘ä»¬ç”¨`swanlab.log`è·Ÿè¸ªå®ƒçš„å˜åŒ–ã€‚

## 2.8 æµ‹è¯•å‡½æ•°

æˆ‘ä»¬å®šä¹‰1ä¸ªæµ‹è¯•å‡½æ•°`test`ï¼š

```python
def test(model, device, test_dataloader, epoch):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for inputs, labels in test_dataloader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    accuracy = correct / total * 100
    print('Accuracy: {:.2f}%'.format(accuracy))
    swanlab.log({"test_acc": accuracy})
```

æµ‹è¯•çš„é€»è¾‘åŒæ ·å¾ˆç®€å•ï¼šæˆ‘ä»¬å¾ªç¯è°ƒç”¨`test_dataloader`ï¼Œå°†æµ‹è¯•é›†çš„å›¾åƒä¼ å…¥åˆ°resnet50æ¨¡å‹ä¸­å¾—åˆ°é¢„æµ‹ç»“æœï¼Œä¸æ ‡ç­¾è¿›è¡Œå¯¹æ¯”ï¼Œè®¡ç®—æ•´ä½“çš„å‡†ç¡®ç‡ã€‚

åœ¨æµ‹è¯•ä¸­æˆ‘ä»¬æœ€å…³å¿ƒçš„æŒ‡æ ‡æ˜¯å‡†ç¡®ç‡`accuracy`ï¼Œæ‰€ä»¥æˆ‘ä»¬ç”¨`swanlab.log`è·Ÿè¸ªå®ƒçš„å˜åŒ–ã€‚

## 2.9 å®Œæ•´è®­ç»ƒä»£ç 

æˆ‘ä»¬ä¸€å…±è®­ç»ƒ`num_epochs`è½®ï¼Œæ¯4è½®è¿›è¡Œæµ‹è¯•ï¼Œå¹¶åœ¨æœ€åä¿å­˜æƒé‡æ–‡ä»¶ï¼š

```python
for epoch in range(1, num_epochs + 1):
    train(model, device, TrainDataLoader, optimizer, criterion, epoch)
    if epoch % 4 == 0: 
        accuracy = test(model, device, ValDataLoader, epoch)

if not os.path.exists("checkpoint"):
    os.makedirs("checkpoint")
torch.save(model.state_dict(), 'checkpoint/latest_checkpoint.pth')
print("Training complete")
```

ç»„åˆåçš„å®Œæ•´`train.py`ä»£ç ï¼š

```python
import torch
import torchvision
from torchvision.models import ResNet50_Weights
import swanlab
from torch.utils.data import DataLoader
from load_datasets_simple import DatasetLoader
import os


# å®šä¹‰è®­ç»ƒå‡½æ•°
def train(model, device, train_dataloader, optimizer, criterion, epoch):
    model.train()
    for iter, (inputs, labels) in enumerate(train_dataloader):
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        print('Epoch [{}/{}], Iteration [{}/{}], Loss: {:.4f}'.format(epoch, num_epochs, iter + 1, len(TrainDataLoader),
                                                                      loss.item()))
        swanlab.log({"train_loss": loss.item()})


# å®šä¹‰æµ‹è¯•å‡½æ•°
def test(model, device, test_dataloader, epoch):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for inputs, labels in test_dataloader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    accuracy = correct / total * 100
    print('Accuracy: {:.2f}%'.format(accuracy))
    swanlab.log({"test_acc": accuracy})


if __name__ == "__main__":
    num_epochs = 20
    lr = 1e-4
    batch_size = 8
    num_classes = 2
    
    # è®¾ç½®device
    try:
        use_mps = torch.backends.mps.is_available()
    except AttributeError:
        use_mps = False

    if torch.cuda.is_available():
        device = "cuda"
    elif use_mps:
        device = "mps"
    else:
        device = "cpu"

    # åˆå§‹åŒ–swanlab
    swanlab.init(
        experiment_name="ResNet50",
        description="Train ResNet50 for cat and dog classification.",
        config={
            "model": "resnet50",
            "optim": "Adam",
            "lr": lr,
            "batch_size": batch_size,
            "num_epochs": num_epochs,
            "num_class": num_classes,
            "device": device,
        }
    )

    TrainDataset = DatasetLoader("datasets/train.csv")
    ValDataset = DatasetLoader("datasets/val.csv")
    TrainDataLoader = DataLoader(TrainDataset, batch_size=batch_size, shuffle=True)
    ValDataLoader = DataLoader(ValDataset, batch_size=batch_size, shuffle=False)

    # è½½å…¥ResNet50æ¨¡å‹
    model = torchvision.models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)

    # å°†å…¨è¿æ¥å±‚æ›¿æ¢ä¸º2åˆ†ç±»
    in_features = model.fc.in_features
    model.fc = torch.nn.Linear(in_features, num_classes)

    model.to(torch.device(device))
    criterion = torch.nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)
    
    # å¼€å§‹è®­ç»ƒ
    for epoch in range(1, num_epochs + 1):
        train(model, device, TrainDataLoader, optimizer, criterion, epoch)  # Train for one epoch

        if epoch % 4 == 0:  # Test every 4 epochs
            accuracy = test(model, device, ValDataLoader, epoch)
    
    # ä¿å­˜æƒé‡æ–‡ä»¶
    if not os.path.exists("checkpoint"):
        os.makedirs("checkpoint")
    torch.save(model.state_dict(), 'checkpoint/latest_checkpoint.pth')
    print("Training complete")
```



## 2.10 å¼€å§‹è®­ç»ƒï¼

ğŸ”¥å®éªŒè¿‡ç¨‹å¯çœ‹è¿™ä¸ªç½‘é¡µï¼š[çŒ«ç‹—åˆ†ç±»ï½œSwanLab](https://swanlab.cn/@ZeyiLin/Cats_Dogs_Classification/runs/jzo93k112f15pmx14vtxf/chart)

å¦‚æœä½ ç¬¬ä¸€æ¬¡ä½¿ç”¨SwanLabï¼Œä½ éœ€è¦å…ˆç™»å½•è´¦å·ï¼Œåœ¨ç»ˆç«¯è¾“å…¥ï¼š
```bash
swanlab login
```

ä¼šè®©ä½ å¡«ä¸€ä¸ªAPI Keyï¼Œå»[SwanLabå®˜ç½‘](https://swanlab.cn)ç™»å½•ä¸€ä¸‹è´¦å·ï¼Œåœ¨è®¾ç½®é¡µé¢å¤åˆ¶API Keyï¼Œç²˜è´´è¿‡æ¥å°±å¯ä»¥ï¼š

![alt text](/readme_files/image-3.png)

ç„¶åï¼Œæˆ‘ä»¬è¿è¡Œtrain.pyï¼š 

![alt text](/readme_files/image-4.png)

è¿™æ—¶å€™ä½ ä¼šåœ¨çœ‹åˆ°åœ¨å¼€å¤´ä¼šç»™åˆ°ä½ ä¸¤ä¸ªé“¾æ¥ï¼Œæˆ‘ä»¬ç‚¹å‡»ç¬¬ä¸€ä¸ªï¼Œé‡Œé¢åŒ…å«äº†è¿™ä¸ªé¡¹ç›®çš„ä¿¡æ¯å’Œä¸€ä¸ªå¯¹æ¯”å®éªŒè¡¨æ ¼ï¼š

![alt text](/readme_files/image-5.png)

æˆ‘ä»¬ç‚¹å¼€1ä¸ªè¿›è¡Œä¸­çš„å®éªŒï¼Œä¼šçœ‹åˆ°train_losså’Œtest_accæ•´ä½“çš„å˜åŒ–æ›²çº¿ï¼Œä»¥åŠæˆ‘ä»¬æµ‹è¯•é›†é‡Œçš„å›¾åƒå’Œå®ƒä»¬å¯¹åº”çš„é¢„æµ‹æ ‡ç­¾ï¼š 

![alt text](/readme_files/image-6.png)

åˆ‡æ¢åˆ°å®éªŒå¡ç‰‡ï¼Œè¿™é‡Œè®°å½•äº†å®éªŒçš„å„ç§ä¿¡æ¯ï¼ŒåŒ…æ‹¬è¶…å‚æ•°ã€æœ€ç»ˆçš„å®éªŒæŒ‡æ ‡ã€å®éªŒçŠ¶æ€ã€è®­ç»ƒæ—¶é•¿ã€Gitä»“åº“é“¾æ¥ã€ä¸»æœºåã€æ“ä½œç³»ç»Ÿã€Pythonç‰ˆæœ¬ã€ç¡¬ä»¶é…ç½®ç­‰ç­‰ã€‚

![alt text](/readme_files/image-7.png)

å¯ä»¥çœ‹åˆ°æ¨¡å‹åœ¨ä¸­å·²ç»è¾¾åˆ°äº†100%çš„æµ‹è¯•å‡†ç¡®ç‡ï¼Œä½†æ˜¯åœ¨æœ€ååè€Œæ‹‰äº†â€”â€”è¿™å¯èƒ½å› ä¸ºè¿‡æ‹Ÿåˆã€ä¹Ÿå¯èƒ½æ˜¯å¸¸è§„çš„æ³¢åŠ¨ï¼Œå°±çœ‹åç»­å¦‚ä½•ä¼˜åŒ–å•¦ï½

![alt text](/readme_files/image-8.png)

è‡³æ­¤æˆ‘ä»¬å®Œæˆäº†æ¨¡å‹çš„è®­ç»ƒå’Œæµ‹è¯•ï¼Œå¾—åˆ°äº†1ä¸ªè¡¨ç°éå¸¸æ£’çš„çŒ«ç‹—åˆ†ç±»æ¨¡å‹ï¼Œæƒé‡ä¿å­˜åœ¨äº†checkpointç›®å½•ä¸‹ã€‚ 

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°±åŸºäºè®­ç»ƒå¥½çš„æƒé‡ï¼Œåˆ›å»º1ä¸ªDemoç½‘é¡µå§ï½


# 3. Gradioæ¼”ç¤ºç¨‹åº

Gradioæ˜¯ä¸€ä¸ªå¼€æºçš„Pythonåº“ï¼Œæ—¨åœ¨å¸®åŠ©æ•°æ®ç§‘å­¦å®¶ã€ç ”ç©¶äººå‘˜å’Œä»äº‹æœºå™¨å­¦ä¹ é¢†åŸŸçš„å¼€å‘äººå‘˜å¿«é€Ÿåˆ›å»ºå’Œå…±äº«ç”¨äºæœºå™¨å­¦ä¹ æ¨¡å‹çš„ç”¨æˆ·ç•Œé¢ã€‚

åœ¨è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨Gradioæ¥æ„å»ºä¸€ä¸ªçŒ«ç‹—åˆ†ç±»çš„Demoç•Œé¢ï¼Œç¼–å†™`app.py`ç¨‹åºï¼š

```python
import gradio as gr
import torch
import torchvision.transforms as transforms
import torch.nn.functional as F
import torchvision

# åŠ è½½ä¸è®­ç»ƒä¸­ä½¿ç”¨çš„ç›¸åŒç»“æ„çš„æ¨¡å‹
def load_model(checkpoint_path, num_classes):
    # åŠ è½½é¢„è®­ç»ƒçš„ResNet50æ¨¡å‹
    try:
        use_mps = torch.backends.mps.is_available()
    except AttributeError:
        use_mps = False

    if torch.cuda.is_available():
        device = "cuda"
    elif use_mps:
        device = "mps"
    else:
        device = "cpu"

    model = torchvision.models.resnet50(weights=None)
    in_features = model.fc.in_features
    model.fc = torch.nn.Linear(in_features, num_classes)
    model.load_state_dict(torch.load(checkpoint_path, map_location=device))
    model.eval()  # Set model to evaluation mode
    return model

# åŠ è½½å›¾åƒå¹¶æ‰§è¡Œå¿…è¦çš„è½¬æ¢çš„å‡½æ•°
def process_image(image, image_size):
    # Define the same transforms as used during training
    preprocessing = transforms.Compose([
        transforms.Resize((image_size, image_size)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])
    image = preprocessing(image).unsqueeze(0)
    return image


# é¢„æµ‹å›¾åƒç±»åˆ«å¹¶è¿”å›æ¦‚ç‡çš„å‡½æ•°
def predict(image):
    classes = {'0': 'cat', '1': 'dog'}  # Update or extend this dictionary based on your actual classes
    image = process_image(image, 256)  # Using the image size from training
    with torch.no_grad():
        outputs = model(image)
        probabilities = F.softmax(outputs, dim=1).squeeze()  # Apply softmax to get probabilities
    # Mapping class labels to probabilities
    class_probabilities = {classes[str(i)]: float(prob) for i, prob in enumerate(probabilities)}
    return class_probabilities


# å®šä¹‰åˆ°æ‚¨çš„æ¨¡å‹æƒé‡çš„è·¯å¾„
checkpoint_path = 'checkpoint/latest_checkpoint.pth'
num_classes = 2
model = load_model(checkpoint_path, num_classes)

# å®šä¹‰Gradio Interface
iface = gr.Interface(
    fn=predict,
    inputs=gr.Image(type="pil"),
    outputs=gr.Label(num_top_classes=num_classes),
    title="Cat vs Dog Classifier",
)

if __name__ == "__main__":
    iface.launch()
```

è¿è¡Œç¨‹åºåï¼Œä¼šå‡ºç°ä»¥ä¸‹è¾“å‡ºï¼š

![alt text](/readme_files/image-9.png)

ç‚¹å¼€é“¾æ¥ï¼Œå‡ºç°çŒ«ç‹—åˆ†ç±»çš„Demoç½‘é¡µï¼š

![alt text](/readme_files/image-10.png)

ç”¨çŒ«å’Œç‹—çš„å›¾ç‰‡è¯•è¯•ï¼š

![alt text](/readme_files/image-11.png)

![alt text](/readme_files/image-12.png)

æ•ˆæœå¾ˆå®Œç¾ï¼

è‡³æ­¤ï¼Œæˆ‘ä»¬å®Œæˆäº†ç”¨PyTorchã€SwanLabã€Gradioä¸‰ä¸ªå¼€æºå·¥å…·è®­ç»ƒ1ä¸ªçŒ«ç‹—åˆ†ç±»æ¨¡å‹çš„å…¨éƒ¨è¿‡ç¨‹ï¼Œæ›´å¤šæƒ³äº†è§£çš„å¯ä»¥å‚è€ƒç›¸å…³é“¾æ¥æˆ–è¯„è®ºæ­¤æ–‡ç« ã€‚

å¦‚æœæœ‰å¸®åŠ©ï¼Œè¯·Starå§ï½
